[package]
name = "inferno-llama"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
repository.workspace = true
description = "Native BF16/F16 Llama implementation for high-performance distributed systems"

[dependencies]
# Core candle dependencies for tensor operations
candle-core = { workspace = true }
candle-nn = { workspace = true }
candle-transformers = { workspace = true }

# Workspace dependencies
thiserror = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }

# Math and precision support
half = { workspace = true }
bytemuck = { workspace = true }
regex = { workspace = true }

# For configuration loading
hf-hub = { workspace = true }
safetensors = { workspace = true }

# For tokenization support
tokenizers = { workspace = true }
tracing = { workspace = true }
tokio = { workspace = true }

[dev-dependencies]
criterion = { workspace = true }
proptest = { workspace = true }
tokio-test = { workspace = true }
tokio = { workspace = true }
rstest = { workspace = true }
tempfile = { workspace = true }


[package.metadata.cargo-machete]
ignored = ["bytemuck", "candle-nn", "half", "hf-hub", "safetensors", "regex"]

